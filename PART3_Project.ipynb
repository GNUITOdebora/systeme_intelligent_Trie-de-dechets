{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\images.jpg: 384x640 1 cup, 1 spoon, 4 oranges, 104.5ms\n",
      "Speed: 15.9ms preprocess, 104.5ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_1.jpg: 640x480 1 person, 1 bottle, 1 pizza, 1 dining table, 1 vase, 63.5ms\n",
      "Speed: 2.0ms preprocess, 63.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Image: image_1.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_10.jpg: 640x480 1 bottle, 58.3ms\n",
      "Speed: 0.6ms preprocess, 58.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Image: image_10.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_11.jpg: 640x480 (no detections), 76.6ms\n",
      "Speed: 2.7ms preprocess, 76.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_12.jpg: 640x480 (no detections), 57.2ms\n",
      "Speed: 0.0ms preprocess, 57.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_13.jpg: 480x640 5 bottles, 1 refrigerator, 68.7ms\n",
      "Speed: 2.0ms preprocess, 68.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Image: image_13.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_14.jpg: 640x480 1 bottle, 1 apple, 61.9ms\n",
      "Speed: 0.0ms preprocess, 61.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Image: image_14.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: orange - Classe: Organic\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_15.jpg: 640x480 1 person, 1 remote, 47.9ms\n",
      "Speed: 4.6ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_16.jpg: 640x480 3 bottles, 46.1ms\n",
      "Speed: 1.9ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Image: image_16.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_17.jpg: 640x480 1 person, 1 bottle, 1 chair, 1 dining table, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Image: image_17.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: plastic - Classe: Recyclable\n",
      "Objet détecté: cardboard - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_18.jpg: 640x480 (no detections), 47.7ms\n",
      "Speed: 0.0ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_19.jpg: 640x480 (no detections), 47.1ms\n",
      "Speed: 0.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_2.jpg: 640x480 1 book, 47.2ms\n",
      "Speed: 0.0ms preprocess, 47.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_20.jpg: 640x480 1 umbrella, 47.1ms\n",
      "Speed: 0.0ms preprocess, 47.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_21.jpg: 480x640 1 suitcase, 2 cups, 1 dining table, 50.3ms\n",
      "Speed: 0.6ms preprocess, 50.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_22.jpg: 480x640 1 cup, 1 dining table, 48.4ms\n",
      "Speed: 1.0ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_23.jpg: 640x480 1 bottle, 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Image: image_23.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_24.jpg: 640x480 2 bottles, 60.6ms\n",
      "Speed: 0.0ms preprocess, 60.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Image: image_24.jpg\n",
      "Objet détecté: bottle - Classe: Organic\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_25.jpg: 640x480 1 person, 1 remote, 1 cell phone, 59.8ms\n",
      "Speed: 0.0ms preprocess, 59.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Image: image_25.jpg\n",
      "Objet détecté: paper - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_26.jpg: 480x640 (no detections), 61.7ms\n",
      "Speed: 1.0ms preprocess, 61.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_27.jpg: 480x640 (no detections), 58.2ms\n",
      "Speed: 0.0ms preprocess, 58.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_28.jpg: 640x480 (no detections), 58.3ms\n",
      "Speed: 0.0ms preprocess, 58.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_29.jpg: 640x480 (no detections), 54.5ms\n",
      "Speed: 0.0ms preprocess, 54.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_3.jpg: 640x480 1 bed, 56.7ms\n",
      "Speed: 0.0ms preprocess, 56.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_30.jpg: 640x480 (no detections), 54.3ms\n",
      "Speed: 2.0ms preprocess, 54.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_31.jpg: 640x480 (no detections), 54.7ms\n",
      "Speed: 1.7ms preprocess, 54.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_32.jpg: 640x480 (no detections), 53.9ms\n",
      "Speed: 2.2ms preprocess, 53.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_33.jpg: 640x480 1 surfboard, 60.4ms\n",
      "Speed: 2.0ms preprocess, 60.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_34.jpg: 480x640 (no detections), 72.2ms\n",
      "Speed: 0.0ms preprocess, 72.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_35.jpg: 640x480 1 person, 1 remote, 64.1ms\n",
      "Speed: 0.0ms preprocess, 64.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_36.jpg: 640x480 1 person, 1 bottle, 1 dining table, 1 mouse, 63.7ms\n",
      "Speed: 1.0ms preprocess, 63.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Image: image_36.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_37.jpg: 640x480 (no detections), 56.1ms\n",
      "Speed: 8.1ms preprocess, 56.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_38.jpg: 640x480 (no detections), 53.6ms\n",
      "Speed: 2.0ms preprocess, 53.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_39.jpg: 640x480 (no detections), 56.2ms\n",
      "Speed: 2.0ms preprocess, 56.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_4.jpg: 480x640 (no detections), 72.1ms\n",
      "Speed: 0.0ms preprocess, 72.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_40.jpg: 640x480 (no detections), 59.0ms\n",
      "Speed: 0.0ms preprocess, 59.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_41.jpg: 640x480 (no detections), 62.2ms\n",
      "Speed: 1.6ms preprocess, 62.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_42.jpg: 640x480 (no detections), 62.1ms\n",
      "Speed: 0.3ms preprocess, 62.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_43.jpg: 640x480 (no detections), 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_44.jpg: 640x480 2 bottles, 1 sink, 59.7ms\n",
      "Speed: 2.0ms preprocess, 59.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Image: image_44.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_45.jpg: 480x640 1 bottle, 85.3ms\n",
      "Speed: 2.0ms preprocess, 85.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "Image: image_45.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_46.jpg: 480x640 (no detections), 138.7ms\n",
      "Speed: 2.0ms preprocess, 138.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_47.jpg: 480x640 3 bottles, 1 remote, 113.7ms\n",
      "Speed: 2.0ms preprocess, 113.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Image: image_47.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_48.jpg: 480x640 1 cup, 1 clock, 52.6ms\n",
      "Speed: 1.0ms preprocess, 52.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_49.jpg: 480x640 (no detections), 62.4ms\n",
      "Speed: 2.0ms preprocess, 62.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_5.jpg: 640x480 (no detections), 69.2ms\n",
      "Speed: 1.2ms preprocess, 69.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_50.jpg: 640x480 1 person, 1 couch, 1 book, 1 teddy bear, 66.8ms\n",
      "Speed: 3.7ms preprocess, 66.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Image: image_50.jpg\n",
      "Objet détecté: glass - Classe: Organic\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_51.jpg: 640x480 (no detections), 93.8ms\n",
      "Speed: 1.7ms preprocess, 93.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_52.jpg: 640x480 (no detections), 78.9ms\n",
      "Speed: 2.5ms preprocess, 78.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_53.jpg: 640x480 1 knife, 64.2ms\n",
      "Speed: 2.0ms preprocess, 64.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Image: image_53.jpg\n",
      "Objet détecté: banana - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_54.jpg: 640x480 (no detections), 110.5ms\n",
      "Speed: 1.0ms preprocess, 110.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_55.jpg: 640x480 (no detections), 75.2ms\n",
      "Speed: 1.8ms preprocess, 75.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_56.jpg: 640x480 (no detections), 58.9ms\n",
      "Speed: 2.5ms preprocess, 58.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_57.jpg: 640x480 1 car, 58.3ms\n",
      "Speed: 2.0ms preprocess, 58.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_58.jpg: 640x480 (no detections), 59.9ms\n",
      "Speed: 0.0ms preprocess, 59.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_59.jpg: 640x480 1 person, 60.3ms\n",
      "Speed: 2.0ms preprocess, 60.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_6.jpg: 480x640 2 cups, 1 dining table, 85.3ms\n",
      "Speed: 0.0ms preprocess, 85.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_60.jpg: 640x480 (no detections), 74.9ms\n",
      "Speed: 2.0ms preprocess, 74.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_61.jpg: 640x480 (no detections), 62.2ms\n",
      "Speed: 0.0ms preprocess, 62.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_62.jpg: 640x480 (no detections), 64.1ms\n",
      "Speed: 2.0ms preprocess, 64.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_63.jpg: 640x480 1 cat, 63.9ms\n",
      "Speed: 2.0ms preprocess, 63.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_64.jpg: 640x480 (no detections), 60.3ms\n",
      "Speed: 1.0ms preprocess, 60.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_65.jpg: 640x480 (no detections), 71.1ms\n",
      "Speed: 1.0ms preprocess, 71.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_66.jpg: 640x480 (no detections), 54.5ms\n",
      "Speed: 1.1ms preprocess, 54.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_67.jpg: 640x480 1 suitcase, 66.3ms\n",
      "Speed: 0.0ms preprocess, 66.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_68.jpg: 640x480 1 bottle, 1 cup, 64.7ms\n",
      "Speed: 2.0ms preprocess, 64.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Image: image_68.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_69.jpg: 640x480 1 cup, 1 knife, 86.4ms\n",
      "Speed: 0.0ms preprocess, 86.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Image: image_69.jpg\n",
      "Objet détecté: banana - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_7.jpg: 640x480 1 person, 1 bottle, 75.5ms\n",
      "Speed: 1.3ms preprocess, 75.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Image: image_7.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_70.jpg: 480x640 (no detections), 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_71.jpg: 640x480 1 book, 73.0ms\n",
      "Speed: 0.0ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_8.jpg: 480x640 (no detections), 96.3ms\n",
      "Speed: 2.0ms preprocess, 96.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\image_9.jpg: 640x480 1 bottle, 90.5ms\n",
      "Speed: 2.0ms preprocess, 90.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Image: image_9.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\O_1 copy.jpg: 640x576 1 orange, 103.4ms\n",
      "Speed: 7.8ms preprocess, 103.4ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\O_1.jpg: 640x576 1 orange, 105.8ms\n",
      "Speed: 5.4ms preprocess, 105.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\O_2.jpg: 448x640 1 apple, 80.3ms\n",
      "Speed: 2.1ms preprocess, 80.3ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Image: O_2.jpg\n",
      "Objet détecté: orange - Classe: Organic\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\O_3.jpg: 448x640 1 apple, 1 orange, 57.1ms\n",
      "Speed: 2.2ms preprocess, 57.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Image: O_3.jpg\n",
      "Objet détecté: orange - Classe: Organic\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\O_4.jpg: 640x640 1 apple, 173.1ms\n",
      "Speed: 3.6ms preprocess, 173.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Image: O_4.jpg\n",
      "Objet détecté: orange - Classe: Organic\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\O_5.jpg: 448x640 1 orange, 68.9ms\n",
      "Speed: 1.2ms preprocess, 68.9ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\O_6.jpg: 448x640 1 orange, 59.5ms\n",
      "Speed: 2.0ms preprocess, 59.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\O_7.jpg: 576x640 1 vase, 112.1ms\n",
      "Speed: 5.2ms preprocess, 112.1ms inference, 0.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\O_8.jpg: 640x640 1 vase, 71.5ms\n",
      "Speed: 4.0ms preprocess, 71.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\R_1.jpg: 352x640 2 persons, 76.6ms\n",
      "Speed: 2.0ms preprocess, 76.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\R_2.jpg: 640x448 1 vase, 86.2ms\n",
      "Speed: 2.0ms preprocess, 86.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\R_3 copy.jpg: 480x640 1 kite, 81.6ms\n",
      "Speed: 2.0ms preprocess, 81.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\R_3.jpg: 480x640 1 kite, 66.4ms\n",
      "Speed: 2.4ms preprocess, 66.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\R_4.jpg: 448x640 2 persons, 1 snowboard, 63.2ms\n",
      "Speed: 2.0ms preprocess, 63.2ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 B:\\computerVISIONFINALE\\images\\R_5.jpg: 448x640 2 bottles, 2 vases, 66.7ms\n",
      "Speed: 1.0ms preprocess, 66.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Image: R_5.jpg\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n",
      "Objet détecté: bottle - Classe: Recyclable\n",
      "Objet détecté: can - Classe: Recyclable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Charger le modèle SVM\n",
    "svm_model_path = 'B:\\\\computerVISIONFINALE\\\\best_svm_resnet.pkl'  # Remplacez par le chemin de votre modèle SVM\n",
    "svm_model = joblib.load(svm_model_path)\n",
    "\n",
    "# Charger le modèle YOLOv8\n",
    "model = YOLO(\"yolov8n.pt\")  # Utilisez yolov8n.pt pour un modèle léger ou un autre modèle selon vos besoins\n",
    "\n",
    "# Liste des déchets spécifiques à détecter\n",
    "waste_objects = [\n",
    "    'plastic',  # Plastique\n",
    "    'paper',    # Papier\n",
    "    'fruit',    # Fruits\n",
    "    'bottle',   # Bouteille\n",
    "    'glass',    # Verre\n",
    "    'cardboard',# Carton\n",
    "    'can',      # Canette\n",
    "    'metal',    \n",
    "    'orange',   # Orange\n",
    "    'banana'    # Banane\n",
    "]\n",
    "\n",
    "# Dictionnaire des classes YOLO correspondantes (exemple basé sur COCO ou classes personnalisées)\n",
    "yolo_class_dict = {\n",
    "    'plastic': 56,    # Classe pour le plastique (exemple d'ID COCO)\n",
    "    'paper': 67,      # Classe pour le papier\n",
    "    'fruit': 52,      # Classe pour les fruits (exemple)\n",
    "    'bottle': 39,     # Classe pour la bouteille\n",
    "    'glass': 77,      # Classe pour le verre\n",
    "    'cardboard': 56,  # Classe pour le carton\n",
    "    'can': 39,        # Classe pour la canette\n",
    "    'metal': 40,      # Classe pour le métal\n",
    "    'orange': 47,     # Classe pour l'orange (à vérifier)\n",
    "    'banana': 43      # Classe pour la banane (à vérifier)\n",
    "}\n",
    "\n",
    "# Charger le modèle ResNet50 pré-entraîné de TensorFlow\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')  # Utiliser le modèle sans la couche finale\n",
    "\n",
    "# Fonction pour appliquer YOLOv8 sur une image et détecter les objets spécifiques\n",
    "def detect_objects_yolov8(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Utiliser YOLOv8 pour détecter les objets dans l'image\n",
    "    results = model.predict(image_path)  # Utiliser predict au lieu de img_path\n",
    "\n",
    "    # Extraire les résultats des détections\n",
    "    boxes = results[0].boxes  # Boîtes englobantes des objets détectés\n",
    "    class_ids = boxes.cls  # Classes des objets détectés\n",
    "    confidences = boxes.conf  # Confiances des détections\n",
    "\n",
    "    return boxes, class_ids, confidences, img_rgb\n",
    "\n",
    "# Fonction pour extraire les caractéristiques d'un objet pour la classification SVM\n",
    "def extract_features_for_svm(object_image):\n",
    "    # Convertir l'image de BGR à RGB si nécessaire\n",
    "    if object_image.shape[2] == 3:  # Vérifiez si l'image a 3 canaux (RGB)\n",
    "        object_image = cv2.cvtColor(object_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Redimensionner l'image pour qu'elle corresponde à la taille attendue par ResNet50\n",
    "    object_image = cv2.resize(object_image, (224, 224))  # 224x224 est la taille d'entrée attendue\n",
    "    img_array = image.img_to_array(object_image)  # Convertir l'image en tableau numpy\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Ajouter une dimension pour le batch\n",
    "    img_array = preprocess_input(img_array)  # Appliquer la prétraitement spécifique à ResNet50\n",
    "\n",
    "    # Passer l'image à travers le modèle ResNet50 pour obtenir les caractéristiques\n",
    "    features = resnet_model.predict(img_array)  # Extraire les caractéristiques\n",
    "    return features.flatten()  # Aplatir la sortie et la convertir en numpy\n",
    "\n",
    "# Fonction principale pour traiter les images et prédire les classes avec YOLOv8 et SVM\n",
    "def process_images(image_dir, output_dir):\n",
    "    # Créer le dossier de sortie si nécessaire\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    image_count = 0\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Charger l'image\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            boxes, class_ids, confidences, img_rgb = detect_objects_yolov8(image_path)\n",
    "\n",
    "            # Filtrer les objets selon la liste de déchets\n",
    "            detected_objects = []\n",
    "            for i, class_id in enumerate(class_ids):\n",
    "                # Vérifier si l'objet détecté est dans notre liste\n",
    "                for obj in waste_objects:\n",
    "                    if int(class_id) == yolo_class_dict.get(obj):\n",
    "                        # Extraire les coordonnées de la boîte englobante\n",
    "                        x1, y1, x2, y2 = boxes[i].xyxy[0].cpu().numpy()  # Convertir en liste pour un déballage correct\n",
    "\n",
    "                        # Extraire l'objet de l'image\n",
    "                        object_image = img_rgb[int(y1):int(y2), int(x1):int(x2)]\n",
    "\n",
    "                        # Extraire les caractéristiques de l'objet\n",
    "                        features = extract_features_for_svm(object_image)\n",
    "\n",
    "                        # Classifier l'objet avec le modèle SVM\n",
    "                        prediction = svm_model.predict([features])\n",
    "\n",
    "                        # Afficher le résultat de la classification\n",
    "                        if prediction == 0:\n",
    "                            label = \"Recyclable\"\n",
    "                        else:\n",
    "                            label = \"Organic\"\n",
    "                        \n",
    "                        detected_objects.append((obj, label))\n",
    "\n",
    "                        # Choisir la couleur de la boîte en fonction de l'étiquette\n",
    "                        if label == \"Organic\":\n",
    "                            color = (255, 0, 0)  # Bleu pour \"Organic\"\n",
    "                        else:\n",
    "                            color = (0, 255, 0)  # Vert pour \"Recyclable\"\n",
    "\n",
    "                        # Dessiner une boîte englobante et un label sur l'image\n",
    "                        cv2.rectangle(img_rgb, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                        cv2.putText(img_rgb, f\"{label}\", (int(x1), int(y1) - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Si des objets ont été détectés, afficher l'image et les résultats\n",
    "            if detected_objects:\n",
    "                print(f\"Image: {filename}\")\n",
    "                for obj, label in detected_objects:\n",
    "                    print(f\"Objet détecté: {obj} - Classe: {label}\")\n",
    "\n",
    "                # Enregistrer l'image annotée dans le dossier de sortie\n",
    "                output_path = os.path.join(output_dir, f\"processed_{filename}\")\n",
    "                cv2.imwrite(output_path, cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                # Incrémenter le compteur d'images traitées\n",
    "                image_count += 1\n",
    "\n",
    "\n",
    "# Répertoire d'images à traiter\n",
    "image_dir = r'B:\\\\computerVISIONFINALE\\\\images'  # Chemin vers le répertoire contenant les images\n",
    "\n",
    "# Dossier de sortie pour les images annotées\n",
    "output_dir = r'B:\\\\computerVISIONFINALE\\\\output_images'  # Remplacez par le chemin de votre dossier de sortie\n",
    "\n",
    "# Appliquer la détection et la classification\n",
    "process_images(image_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to B:\\\\computerVISIONFINALE\\\\final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Fonction pour sauvegarder le modèle YOLO et SVM ensemble\n",
    "def save_final_model(yolo_model_path, svm_model_path, final_model_path):\n",
    "    final_model = {\n",
    "        \"yolo_model_path\": yolo_model_path,\n",
    "        \"svm_model_path\": svm_model_path,\n",
    "        \"resnet_model\": resnet_model\n",
    "    }\n",
    "    with open(final_model_path, 'wb') as file:\n",
    "        pickle.dump(final_model, file)\n",
    "    print(f\"Final model saved to {final_model_path}\")\n",
    "\n",
    "# Sauvegarder le modèle final\n",
    "final_model_path = r'B:\\\\computerVISIONFINALE\\\\final_model.pkl'  # Chemin où le modèle sera sauvegardé\n",
    "save_final_model(\"yolov8n.pt\", svm_model_path, final_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
