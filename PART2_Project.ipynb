{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for label in [\"R\", \"O\"]:\n",
    "        path = os.path.join(directory, label)\n",
    "        for file in os.listdir(path):\n",
    "            img_path = os.path.join(path, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (128, 128))  # Taille arbitraire\n",
    "                data.append(img)\n",
    "                labels.append(0 if label == \"R\" else 1)  # 0 pour 'R', 1 pour 'O'\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Détection de caractéristiques spatiales avec des réseaux de neurones profonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser une architecture CNN comme ResNet et VGG pour extraire des caractéristiques de haut niveau des images. Par exemple, vous pouvez utiliser un modèle pré-entrainé comme ResNet50 de Keras et l'adapter pour votre tâche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionner les images à la taille appropriée\n",
    "def resize_for_model(data, target_size=(224, 224)):\n",
    "    resized_data = []\n",
    "    for img in data:\n",
    "        resized_img = cv2.resize(img, target_size)  # VGG16 et ResNet50 attendent 224x224\n",
    "        resized_data.append(resized_img)\n",
    "    return np.array(resized_data)\n",
    "\n",
    "# Fonction pour extraire les caractéristiques avec ResNet50 ou VGG16\n",
    "def extract_features(model, preprocess_func, data):\n",
    "    data_preprocessed = preprocess_func(data)  # Prétraitement spécifique au modèle\n",
    "    features = model.predict(data_preprocessed)  # Extraction des caractéristiques\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour ResNet50 et VGG16\n",
    "def prepare_data_for_models(X_train, X_test):\n",
    "    print(\"Préparation des données...\")\n",
    "    X_train_resized = resize_for_model(X_train)\n",
    "    X_test_resized = resize_for_model(X_test)\n",
    "\n",
    "    # Charger les modèles pré-entraînés\n",
    "    resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    vgg_model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    print(\"Extraction des caractéristiques avec ResNet50...\")\n",
    "    X_train_resnet = extract_features(resnet_model, preprocess_resnet, X_train_resized)\n",
    "    X_test_resnet = extract_features(resnet_model, preprocess_resnet, X_test_resized)\n",
    "\n",
    "    print(\"Extraction des caractéristiques avec VGG16...\")\n",
    "    X_train_vgg = extract_features(vgg_model, preprocess_vgg, X_train_resized)\n",
    "    X_test_vgg = extract_features(vgg_model, preprocess_vgg, X_test_resized)\n",
    "\n",
    "    # Retourner les caractéristiques extraites séparément pour chaque modèle\n",
    "    return X_train_resnet, X_test_resnet, X_train_vgg, X_test_vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTARINEMENT DES MODELES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train_features, y_train, classifier_type='knn'):\n",
    "    if classifier_type == 'knn':\n",
    "        clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif classifier_type == 'rf':\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif classifier_type == 'xgb':\n",
    "        clf = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    elif classifier_type == 'svm':\n",
    "        clf = SVC(random_state=42)\n",
    "    else:\n",
    "        raise ValueError(f\"Classificateur {classifier_type} non supporté\")\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    clf.fit(X_train_features, y_train)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION DES MODELES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction d'évaluation du modèle\n",
    "def evaluate_classifier(clf, X_test_features, y_test):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Prédiction des labels sur les données de test\n",
    "    y_pred = clf.predict(X_test_features)\n",
    "\n",
    "    # Calcul de la précision\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Durée de l'évaluation\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    return accuracy, duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exécution du processus complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation des données...\n",
      "Extraction des caractéristiques avec ResNet50...\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 1s/step\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step\n",
      "Extraction des caractéristiques avec VGG16...\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1088s\u001b[0m 3s/step\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 3s/step\n",
      "Résultats pour ResNet50 :\n",
      "Précision KNN : 0.9570, Temps : 2.6875\n",
      "Précision SVM : 0.9702, Temps : 18.6723\n",
      "Précision XGBoost : 0.9568, Temps : 0.0444\n",
      "Précision RandomForest : 0.9435, Temps : 0.1884\n",
      "\n",
      "Résultats pour VGG16 :\n",
      "Précision KNN : 0.9374, Temps : 0.5265\n",
      "Précision SVM : 0.9550, Temps : 5.7880\n",
      "Précision XGBoost : 0.9453, Temps : 0.0147\n",
      "Précision RandomForest : 0.9238, Temps : 0.11669182777404785\n"
     ]
    }
   ],
   "source": [
    "# Chemins des répertoires d'entraînement et de test\n",
    "train_dir = r\"B:\\computerVISIONFINALE\\Train\"\n",
    "test_dir = r\"B:\\computerVISIONFINALE\\Test\"\n",
    "\n",
    "# Charger les données\n",
    "X_train, y_train = load_data(train_dir)\n",
    "X_test, y_test = load_data(test_dir)\n",
    "\n",
    "# Préparer les données pour ResNet50 et VGG16\n",
    "X_train_resnet, X_test_resnet, X_train_vgg, X_test_vgg = prepare_data_for_models(X_train, X_test)\n",
    "\n",
    "# Entraîner et évaluer les modèles pour ResNet50\n",
    "clf_knn_resnet = train_classifier(X_train_resnet, y_train, classifier_type='knn')\n",
    "clf_svm_resnet = train_classifier(X_train_resnet, y_train, classifier_type='svm')\n",
    "clf_xgb_resnet = train_classifier(X_train_resnet, y_train, classifier_type='xgb')\n",
    "clf_rf_resnet = train_classifier(X_train_resnet, y_train, classifier_type='rf')\n",
    "\n",
    "accuracy_knn_resnet, duration_knn_resnet = evaluate_classifier(clf_knn_resnet, X_test_resnet, y_test)\n",
    "accuracy_svm_resnet, duration_svm_resnet = evaluate_classifier(clf_svm_resnet, X_test_resnet, y_test)\n",
    "accuracy_xgb_resnet, duration_xgb_resnet = evaluate_classifier(clf_xgb_resnet, X_test_resnet, y_test)\n",
    "accuracy_rf_resnet, duration_rf_resnet = evaluate_classifier(clf_rf_resnet, X_test_resnet, y_test)\n",
    "\n",
    "# Entraîner et évaluer les modèles pour VGG16\n",
    "clf_knn_vgg = train_classifier(X_train_vgg, y_train, classifier_type='knn')\n",
    "clf_svm_vgg = train_classifier(X_train_vgg, y_train, classifier_type='svm')\n",
    "clf_xgb_vgg = train_classifier(X_train_vgg, y_train, classifier_type='xgb')\n",
    "clf_rf_vgg = train_classifier(X_train_vgg, y_train, classifier_type='rf')\n",
    "\n",
    "accuracy_knn_vgg, duration_knn_vgg = evaluate_classifier(clf_knn_vgg, X_test_vgg, y_test)\n",
    "accuracy_svm_vgg, duration_svm_vgg = evaluate_classifier(clf_svm_vgg, X_test_vgg, y_test)\n",
    "accuracy_xgb_vgg, duration_xgb_vgg = evaluate_classifier(clf_xgb_vgg, X_test_vgg, y_test)\n",
    "accuracy_rf_vgg, duration_rf_vgg = evaluate_classifier(clf_rf_vgg, X_test_vgg, y_test)\n",
    "\n",
    "# Afficher les résultats pour ResNet50 et VGG16\n",
    "print(\"Résultats pour ResNet50 :\")\n",
    "print(f\"Précision KNN : {accuracy_knn_resnet:.4f}, Temps : {duration_knn_resnet:.4f}\")\n",
    "print(f\"Précision SVM : {accuracy_svm_resnet:.4f}, Temps : {duration_svm_resnet:.4f}\")\n",
    "print(f\"Précision XGBoost : {accuracy_xgb_resnet:.4f}, Temps : {duration_xgb_resnet:.4f}\")\n",
    "print(f\"Précision RandomForest : {accuracy_rf_resnet:.4f}, Temps : {duration_rf_resnet:.4f}\")\n",
    "\n",
    "print(\"\\nRésultats pour VGG16 :\")\n",
    "print(f\"Précision KNN : {accuracy_knn_vgg:.4f}, Temps : {duration_knn_vgg:.4f}\")\n",
    "print(f\"Précision SVM : {accuracy_svm_vgg:.4f}, Temps : {duration_svm_vgg:.4f}\")\n",
    "print(f\"Précision XGBoost : {accuracy_xgb_vgg:.4f}, Temps : {duration_xgb_vgg:.4f}\")\n",
    "print(f\"Précision RandomForest : {accuracy_rf_vgg:.4f}, Temps : {duration_rf_vgg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats pour ResNet50 :\n",
      "\n",
      "KNN - ResNet50:\n",
      "Précision : 0.9570, Temps : 2.6875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      2133\n",
      "           1       0.95      0.97      0.96      2931\n",
      "\n",
      "    accuracy                           0.96      5064\n",
      "   macro avg       0.96      0.95      0.96      5064\n",
      "weighted avg       0.96      0.96      0.96      5064\n",
      "\n",
      "\n",
      "SVM - ResNet50:\n",
      "Précision : 0.9702, Temps : 18.6723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      2133\n",
      "           1       0.97      0.98      0.97      2931\n",
      "\n",
      "    accuracy                           0.97      5064\n",
      "   macro avg       0.97      0.97      0.97      5064\n",
      "weighted avg       0.97      0.97      0.97      5064\n",
      "\n",
      "\n",
      "XGBoost - ResNet50:\n",
      "Précision : 0.9568, Temps : 0.0444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      2133\n",
      "           1       0.95      0.97      0.96      2931\n",
      "\n",
      "    accuracy                           0.96      5064\n",
      "   macro avg       0.96      0.95      0.96      5064\n",
      "weighted avg       0.96      0.96      0.96      5064\n",
      "\n",
      "\n",
      "RandomForest - ResNet50:\n",
      "Précision : 0.9435, Temps : 0.1884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      2133\n",
      "           1       0.93      0.98      0.95      2931\n",
      "\n",
      "    accuracy                           0.94      5064\n",
      "   macro avg       0.95      0.94      0.94      5064\n",
      "weighted avg       0.94      0.94      0.94      5064\n",
      "\n",
      "\n",
      "Résultats pour VGG16 :\n",
      "\n",
      "KNN - VGG16:\n",
      "Précision : 0.9374, Temps : 0.5265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2133\n",
      "           1       0.95      0.94      0.95      2931\n",
      "\n",
      "    accuracy                           0.94      5064\n",
      "   macro avg       0.93      0.94      0.94      5064\n",
      "weighted avg       0.94      0.94      0.94      5064\n",
      "\n",
      "\n",
      "SVM - VGG16:\n",
      "Précision : 0.9550, Temps : 5.7880\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      2133\n",
      "           1       0.96      0.96      0.96      2931\n",
      "\n",
      "    accuracy                           0.95      5064\n",
      "   macro avg       0.95      0.95      0.95      5064\n",
      "weighted avg       0.95      0.95      0.95      5064\n",
      "\n",
      "\n",
      "XGBoost - VGG16:\n",
      "Précision : 0.9453, Temps : 0.0147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      2133\n",
      "           1       0.95      0.96      0.95      2931\n",
      "\n",
      "    accuracy                           0.95      5064\n",
      "   macro avg       0.95      0.94      0.94      5064\n",
      "weighted avg       0.95      0.95      0.95      5064\n",
      "\n",
      "\n",
      "RandomForest - VGG16:\n",
      "Précision : 0.9238, Temps : 0.1167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91      2133\n",
      "           1       0.91      0.96      0.94      2931\n",
      "\n",
      "    accuracy                           0.92      5064\n",
      "   macro avg       0.93      0.92      0.92      5064\n",
      "weighted avg       0.92      0.92      0.92      5064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Afficher les résultats pour ResNet50\n",
    "print(\"Résultats pour ResNet50 :\")\n",
    "# Résultats pour KNN\n",
    "print(\"\\nKNN - ResNet50:\")\n",
    "print(f\"Précision : {accuracy_knn_resnet:.4f}, Temps : {duration_knn_resnet:.4f}\")\n",
    "y_pred_knn_resnet = clf_knn_resnet.predict(X_test_resnet)\n",
    "print(classification_report(y_test, y_pred_knn_resnet))\n",
    "\n",
    "# Résultats pour SVM\n",
    "print(\"\\nSVM - ResNet50:\")\n",
    "print(f\"Précision : {accuracy_svm_resnet:.4f}, Temps : {duration_svm_resnet:.4f}\")\n",
    "y_pred_svm_resnet = clf_svm_resnet.predict(X_test_resnet)\n",
    "print(classification_report(y_test, y_pred_svm_resnet))\n",
    "\n",
    "# Résultats pour XGBoost\n",
    "print(\"\\nXGBoost - ResNet50:\")\n",
    "print(f\"Précision : {accuracy_xgb_resnet:.4f}, Temps : {duration_xgb_resnet:.4f}\")\n",
    "y_pred_xgb_resnet = clf_xgb_resnet.predict(X_test_resnet)\n",
    "print(classification_report(y_test, y_pred_xgb_resnet))\n",
    "\n",
    "# Résultats pour RandomForest\n",
    "print(\"\\nRandomForest - ResNet50:\")\n",
    "print(f\"Précision : {accuracy_rf_resnet:.4f}, Temps : {duration_rf_resnet:.4f}\")\n",
    "y_pred_rf_resnet = clf_rf_resnet.predict(X_test_resnet)\n",
    "print(classification_report(y_test, y_pred_rf_resnet))\n",
    "\n",
    "# Afficher les résultats pour VGG16\n",
    "print(\"\\nRésultats pour VGG16 :\")\n",
    "# Résultats pour KNN\n",
    "print(\"\\nKNN - VGG16:\")\n",
    "print(f\"Précision : {accuracy_knn_vgg:.4f}, Temps : {duration_knn_vgg:.4f}\")\n",
    "y_pred_knn_vgg = clf_knn_vgg.predict(X_test_vgg)\n",
    "print(classification_report(y_test, y_pred_knn_vgg))\n",
    "\n",
    "# Résultats pour SVM\n",
    "print(\"\\nSVM - VGG16:\")\n",
    "print(f\"Précision : {accuracy_svm_vgg:.4f}, Temps : {duration_svm_vgg:.4f}\")\n",
    "y_pred_svm_vgg = clf_svm_vgg.predict(X_test_vgg)\n",
    "print(classification_report(y_test, y_pred_svm_vgg))\n",
    "\n",
    "# Résultats pour XGBoost\n",
    "print(\"\\nXGBoost - VGG16:\")\n",
    "print(f\"Précision : {accuracy_xgb_vgg:.4f}, Temps : {duration_xgb_vgg:.4f}\")\n",
    "y_pred_xgb_vgg = clf_xgb_vgg.predict(X_test_vgg)\n",
    "print(classification_report(y_test, y_pred_xgb_vgg))\n",
    "\n",
    "# Résultats pour RandomForest\n",
    "print(\"\\nRandomForest - VGG16:\")\n",
    "print(f\"Précision : {accuracy_rf_vgg:.4f}, Temps : {duration_rf_vgg:.4f}\")\n",
    "y_pred_rf_vgg = clf_rf_vgg.predict(X_test_vgg)\n",
    "print(classification_report(y_test, y_pred_rf_vgg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le meilleur modèle est svm avec une précision de 0.9702.\n",
      "Le modèle a été enregistré sous le nom : best_svm_resnet.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Comparer les précisions pour chaque modèle\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_classifier_type = \"\"\n",
    "best_model_name = \"\"\n",
    "\n",
    "# ResNet50\n",
    "if accuracy_knn_resnet > best_accuracy:\n",
    "    best_accuracy = accuracy_knn_resnet\n",
    "    best_model = clf_knn_resnet\n",
    "    best_classifier_type = 'knn'\n",
    "    best_model_name = 'best_knn_resnet.pkl'\n",
    "\n",
    "if accuracy_svm_resnet > best_accuracy:\n",
    "    best_accuracy = accuracy_svm_resnet\n",
    "    best_model = clf_svm_resnet\n",
    "    best_classifier_type = 'svm'\n",
    "    best_model_name = 'best_svm_resnet.pkl'\n",
    "\n",
    "if accuracy_xgb_resnet > best_accuracy:\n",
    "    best_accuracy = accuracy_xgb_resnet\n",
    "    best_model = clf_xgb_resnet\n",
    "    best_classifier_type = 'xgb'\n",
    "    best_model_name = 'best_xgb_resnet.pkl'\n",
    "\n",
    "if accuracy_rf_resnet > best_accuracy:\n",
    "    best_accuracy = accuracy_rf_resnet\n",
    "    best_model = clf_rf_resnet\n",
    "    best_classifier_type = 'rf'\n",
    "    best_model_name = 'best_rf_resnet.pkl'\n",
    "\n",
    "# VGG16\n",
    "if accuracy_knn_vgg > best_accuracy:\n",
    "    best_accuracy = accuracy_knn_vgg\n",
    "    best_model = clf_knn_vgg\n",
    "    best_classifier_type = 'knn'\n",
    "    best_model_name = 'best_knn_vgg.pkl'\n",
    "\n",
    "if accuracy_svm_vgg > best_accuracy:\n",
    "    best_accuracy = accuracy_svm_vgg\n",
    "    best_model = clf_svm_vgg\n",
    "    best_classifier_type = 'svm'\n",
    "    best_model_name = 'best_svm_vgg.pkl'\n",
    "\n",
    "if accuracy_xgb_vgg > best_accuracy:\n",
    "    best_accuracy = accuracy_xgb_vgg\n",
    "    best_model = clf_xgb_vgg\n",
    "    best_classifier_type = 'xgb'\n",
    "    best_model_name = 'best_xgb_vgg.pkl'\n",
    "\n",
    "if accuracy_rf_vgg > best_accuracy:\n",
    "    best_accuracy = accuracy_rf_vgg\n",
    "    best_model = clf_rf_vgg\n",
    "    best_classifier_type = 'rf'\n",
    "    best_model_name = 'best_rf_vgg.pkl'\n",
    "\n",
    "# Enregistrer le meilleur modèle\n",
    "if best_model is not None:\n",
    "    joblib.dump(best_model, best_model_name)\n",
    "    print(f\"Le meilleur modèle est {best_classifier_type} avec une précision de {best_accuracy:.4f}.\")\n",
    "    print(f\"Le modèle a été enregistré sous le nom : {best_model_name}\")\n",
    "else:\n",
    "    print(\"Aucun modèle n'a été trouvé.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "La classification des images a montré une amélioration significative par rapport à la première partie, grâce à l'utilisation de caractéristiques de haut niveau extraites via un réseau de neurones profond.\n",
    "\n",
    "**Meilleurs Résultats - Partie 1**\n",
    "\n",
    "<img src=\"score_partie1.png\" alt=\"Résultats Partie 1\" width=\"500\" height=\"200\" />\n",
    "\n",
    "\n",
    "**Impact de l'utilisation de ResNet50**\n",
    "\n",
    "L'intégration de caractéristiques de haut niveau, obtenues grâce au réseau de neurones ResNet50, a permis de considérablement affiner les performances du modèle. En particulier :\n",
    "\n",
    "* Amélioration des métriques globales : Les scores de précision, de rappel et de F1-score ont enregistré une nette progression.\n",
    "\n",
    "* Classification plus précise : Le modèle est désormais plus efficace pour différencier les classes \"Recyclable\" et \"Organique\", offrant ainsi une meilleure fiabilité.\n",
    "\n",
    "Cependant, cette amélioration s'accompagne d'une augmentation du temps d'exécution, mettant en évidence la nécessité de compromis entre précision et rapidité selon les exigences du contexte applicatif."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
